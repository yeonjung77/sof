from pathlib import Path
import re

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

DATA_DIR = Path("data")
PDF_FILES = sorted(DATA_DIR.glob("*.pdf"))


def extract_year_from_filename(path: Path):
    # sof21.pdf -> 2021, sof2025.pdf -> 2025 ì´ëŸ° ì‹ìœ¼ë¡œ ì²˜ë¦¬
    digits = re.findall(r"\d+", path.stem)
    if not digits:
        return None
    num = digits[-1]
    if len(num) == 2:
        return 2000 + int(num)
    elif len(num) == 4:
        return int(num)
    return None


def detect_chapter(text: str, current_chapter: str | None):
    """
    í˜ì´ì§€ í…ìŠ¤íŠ¸ ì•ˆì—ì„œ Global Economy / Consumer Shifts / Fashion System
    ê°™ì€ ì±•í„° íƒ€ì´í‹€ì´ ë“±ì¥í•˜ë©´ ê·¸ê±¸ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ì±•í„°ë¥¼ ì—…ë°ì´íŠ¸.
    """
    lower = text.lower()
    if "global economy" in lower:
        return "Global Economy"
    if "consumer shifts" in lower:
        return "Consumer Shifts"
    if "fashion system" in lower:
        return "Fashion System"
    # ëª» ì°¾ìœ¼ë©´ ì§ì „ ì±•í„° ìœ ì§€
    return current_chapter


def load_pdfs_with_metadata():
    docs = []
    for pdf_path in PDF_FILES:
        year = extract_year_from_filename(pdf_path)
        print(f"ğŸ“„ Loading {pdf_path.name} (year={year})")

        loader = PyPDFLoader(str(pdf_path))
        pages = loader.load()

        current_chapter = None
        for page_doc in pages:
            # ì±•í„° ê°ì§€ & ë©”íƒ€ë°ì´í„° ë¶€ì—¬
            current_chapter = detect_chapter(page_doc.page_content, current_chapter)
            page_doc.metadata["year"] = year
            page_doc.metadata["chapter"] = current_chapter
            docs.append(page_doc)

    return docs


def split_documents(docs):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", " ", ""],
    )
    print("âœ‚ï¸ Splitting documents into chunks ...")
    return splitter.split_documents(docs)


def build_vectorstore(splits):
    print("ğŸ§  Loading embedding modelâ€¦")
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    print("ğŸ“¦ Building FAISS vectorstoreâ€¦")
    vs = FAISS.from_documents(splits, embeddings)
    vs.save_local("faiss_index")
    print("âœ… Saved vectorstore to ./faiss_index")


def main():
    if not PDF_FILES:
        print("âŒ data/ í´ë”ì— PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    docs = load_pdfs_with_metadata()
    splits = split_documents(docs)
    build_vectorstore(splits)


if __name__ == "__main__":
    main()
